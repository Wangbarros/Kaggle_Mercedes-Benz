{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "\n",
    "import xgboost as xgb\n",
    "#import autosklearn.regression\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy import stats\n",
    "from tpot import TPOTRegressor\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datapath = 'Data/'\n",
    "test_csv = 'test.csv'\n",
    "train_csv = 'train.csv'\n",
    "sample_csv = 'sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(datapath,train_csv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Variables with letters are categorical. Variables with 0/1 are binary values.')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_int = []\n",
    "tp_float = []\n",
    "tp_obj = []\n",
    "tp_other = []\n",
    "\n",
    "#Getting all variables names, less ID and looking for it types \n",
    "for i in data.columns.to_series()[1:]:\n",
    "    if data[i].dtype == 'int64':\n",
    "        tp_int.append(i)\n",
    "    elif data[i].dtype == 'float64':\n",
    "        tp_float.append(i)\n",
    "    elif data[i].dtype == 'object':\n",
    "        tp_obj.append(i)\n",
    "    else:\n",
    "        tp_other.append(i)\n",
    "        \n",
    "dic = {'tp_int': tp_int, 'tp_float': tp_float, 'tp_obj': tp_obj, 'tp_other': tp_other}\n",
    "\n",
    "print('Categorical:', tp_obj)\n",
    "print('Float:', tp_float)\n",
    "print('Has other type?', tp_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = []\n",
    "binarys = []\n",
    "for i in tp_int:\n",
    "    print('Variable: {}, Min: {}, Max: {} , Unique: {}'.format(i, data[i].min(), data[i].max() ,data[i].unique()))\n",
    "    if data[i].max() == 0:\n",
    "        drop.append(i)\n",
    "    elif data[i].max() == 1 and data[i].min() == 0 and len(data[i].unique()) == 2:\n",
    "        binarys.append(i)\n",
    "    else:\n",
    "        pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Variables only with 0:', drop)\n",
    "\n",
    "if len(drop) + len(binarys) == len(tp_int):\n",
    "    print('All other integer variables are binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dropping variables only with zero\n",
    "data = data.drop(drop, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One hot enconding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best way to work with categorical variables? I don't think is the best in all case. I will study about that\n",
    "\n",
    "for each in tp_obj:\n",
    "    dummies = pd.get_dummies(data[each], prefix=each, drop_first=False)\n",
    "    data = pd.concat([data, dummies], axis=1)\n",
    "\n",
    "data = data.drop(tp_obj, axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(os.path.join(datapath,test_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dropping variables only with zero\n",
    "data_test = data_test.drop(drop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in tp_obj:\n",
    "    dummies = pd.get_dummies(data_test[each], prefix=each, drop_first=False)\n",
    "    data_test = pd.concat([data_test, dummies], axis=1)\n",
    "\n",
    "data_test = data_test.drop(tp_obj, axis=1)\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keeping only columns who are in both data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep = np.intersect1d(data.columns.to_series(), data_test.columns.to_series())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data[np.append(keep,'y')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test = data_test[keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA and ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Got this from https://www.kaggle.com/frednavruzov/baselines-to-start-with-lb-0-56\n",
    "\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "n_comp = 10\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=n_comp, random_state=42)\n",
    "pca2_results_train = pca.fit_transform(data.drop([\"y\"], axis=1))\n",
    "pca2_results_test = pca.transform(data_test)\n",
    "\n",
    "# ICA\n",
    "ica = FastICA(n_components=n_comp, random_state=42)\n",
    "ica2_results_train = ica.fit_transform(data.drop([\"y\"], axis=1))\n",
    "ica2_results_test = ica.transform(data_test)\n",
    "\n",
    "# Append decomposition components to datasets\n",
    "for i in range(1, n_comp+1):\n",
    "    data['pca_' + str(i)] = pca2_results_train[:,i-1]\n",
    "    data_test['pca_' + str(i)] = pca2_results_test[:, i-1]\n",
    "    \n",
    "    data['ica_' + str(i)] = ica2_results_train[:,i-1]\n",
    "    data_test['ica_' + str(i)] = ica2_results_test[:, i-1]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pca_drop = list(data)[1:-101]\n",
    "#print(pca_drop)\n",
    "#print(type(pca_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The guy in the link is only adding new colunms. I think this doesnt make sense (and barely changed the result). \n",
    "\n",
    "#I also created more PCA/ICA features than just 10\n",
    "\n",
    "#data = data.drop(labels = pca_drop, axis = 1)\n",
    "#data_test = data_test.drop(labels = pca_drop, axis = 1)\n",
    "\n",
    "#print(data.head())\n",
    "#print(data_test.head())\n",
    "\n",
    "#This got worse results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data into training/testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features, test_features, train_y, test_y = model_selection.train_test_split(\n",
    "    data, data['y'], test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = train_features.drop(['ID', 'y'], axis = 1).values\n",
    "test_features = test_features.drop(['ID', 'y'], axis = 1).values\n",
    "\n",
    "train_y = train_y.values\n",
    "test_y = test_y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using all Data available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = data['y']\n",
    "\n",
    "train_features = data.drop(['ID', 'y'], axis = 1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "randomforest = RandomForestRegressor(n_estimators=200, max_features='auto', bootstrap=False, \n",
    "                                   oob_score=False, n_jobs=-1, random_state=0).fit(train_features, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "randomforest_score = randomforest.score(test_features, test_y)\n",
    "print('RF Score:', randomforest_score)\n",
    "\n",
    "predict = randomforest.predict(test_features)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(predict, test_y)\n",
    "print('R Square:', r_value**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_test = randomforest.predict(data_test.iloc[:, 1:].values)\n",
    "\n",
    "submission = pd.DataFrame({'ID': data_test['ID'], 'y': predict_test})\n",
    "submission.to_csv(os.path.join(datapath,'submissionrf.csv'), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg_xgb = xgb.sklearn.XGBRegressor(base_score=train_y.mean(),\n",
    "                                        learning_rate = 0.005,\n",
    "                                        n_estimators = 600,\n",
    "                                        subsample = 0.95,\n",
    "                                        max_depth = 4,\n",
    "                                        objective = 'reg:linear',\n",
    "                                        silent = 1).fit(train_features, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rg_xgb_score = rg_xgb.score(test_features, test_y)\n",
    "print('Xgboost Score:', rg_xgb_score)\n",
    "\n",
    "predict = rg_xgb.predict(test_features)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(predict, test_y)\n",
    "print('Xgboost Square:', r_value**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_test = rg_xgb.predict(data_test.iloc[:, 1:].values)\n",
    "\n",
    "submission = pd.DataFrame({'ID': data_test['ID'], 'y': predict_test})\n",
    "submission.to_csv(os.path.join(datapath,'submissionrg_xgb.csv'), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg_tpot = TPOTRegressor(verbosity=2, \n",
    "                        max_time_mins=1, \n",
    "                        max_eval_time_mins=0.1, \n",
    "                        population_size=100,\n",
    "                        generations=200,\n",
    "                        n_jobs = 1)\n",
    "\n",
    "rg_tpot.fit(train_features, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rg_tpot_score = rg_tpot.score(test_features, test_y)\n",
    "print('rg_tpot Score:', rg_tpot_score)\n",
    "\n",
    "predict = rg_tpot.predict(test_features)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(predict, test_y)\n",
    "print('Tpot Square:', r_value**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rg_adboost = AdaBoostRegressor(base_estimator=train_y.mean(),\n",
    "                             n_estimators=200,\n",
    "                             learning_rate=0.1,\n",
    "                             algorithm='SAMME.R',\n",
    "                             random_state=0).fit(train_features, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rg_adboost_score = rg_adboost.score(test_features, test_y)\n",
    "print('rg_adboost Score:', rg_adboost_score)\n",
    "\n",
    "predict = rg_adboost.predict(test_features)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(predict, test_y)\n",
    "print('Adaboost Square:', r_value**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autosklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoskl = autosklearn.regression.AutoSklearnRegressor(time_left_for_this_task=60,\n",
    "                                                               per_run_time_limit=30,\n",
    "                                                               seed=0)\n",
    "\n",
    "autoskl.fit(train_features, train_y, metric=autosklearn.metrics.accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoskl_score = autoskl.score(test_features, test_y)\n",
    "print('autoskl Score:', autoskl_score)\n",
    "\n",
    "predict = autoskl.predict(test_features)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(predict, test_y)\n",
    "print('Autosklearn Square:', r_value**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "#http://scikit-learn.org/stable/modules/ensemble.html#votingclassifier\n",
    "\n",
    "ensemble = VotingRegressor(estimators=[('randomforest', randomforest),\n",
    "                                        ('rg_xgb', rg_xgb),\n",
    "                                        #('rg_tpot', rg_tpot),\n",
    "                                        ('rg_adboost', rg_adboost),\n",
    "                                        ('autoskl', autoskl),\n",
    "                                        ],\n",
    "                            voting='soft',\n",
    "                            weights=[1,2,1,2]).fit(train_features, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble_score = ensemble.score(test_features, test_y)\n",
    "print('ensemble Score:', ensemble_score)\n",
    "\n",
    "predict = ensemble.predict(test_features)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(predict, test_y)\n",
    "print('ensemble Square:', r_value**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tflearn\n",
    "\n",
    "# Define the neural network\n",
    "def build_model():\n",
    "    # This resets all parameters and variables, leave this here\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # Inputs\n",
    "    net = tflearn.input_data([None, train_features.shape[1]])\n",
    "\n",
    "    # Hidden layer(s)\n",
    "    net = tflearn.fully_connected(net, 512, activation='ReLU') \n",
    "    net = tflearn.fully_connected(net, 512, activation='ReLU')\n",
    "    net = tflearn.dropout(net, 0.80)\n",
    "    \n",
    "    # Output layer and training model\n",
    "    net = tflearn.fully_connected(net, 1, activation='linear')\n",
    "    net = tflearn.regression(net, optimizer='sgd', learning_rate=0.1, loss=\"mean_square\")\n",
    "    \n",
    "    model = tflearn.DNN(net)\n",
    "    return model\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_features, train_y, validation_set=0.2, show_metric=True, batch_size=512, n_epoch=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict = model.predict(test_features)\n",
    "predict = [predict[i][0] for i in range(0, len(predict))]\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(predict, test_y)\n",
    "print('R Square:', r_value**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_test = model.predict(data_test.iloc[:, 1:])\n",
    "predict_test = [predict_test[i][0] for i in range(0, len(predict_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'ID': data_test['ID'], 'y': predict_test})\n",
    "print(submission.head())\n",
    "submission.to_csv(os.path.join(datapath,'submissiondp.csv'), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGboost - Kaggle Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ()# mmm, xgboost, loved by everyone ^-^\n",
    "import xgboost as xgb\n",
    "\n",
    "# prepare dict of params for xgboost to run with\n",
    "xgb_params = {\n",
    "    'n_trees': 500, \n",
    "    'eta': 0.005,\n",
    "    'max_depth': 4,\n",
    "    'subsample': 0.95,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'base_score': train_y.mean(), # base prediction = mean(target)\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "# form DMatrices for Xgboost training\n",
    "dtrain = xgb.DMatrix(train_features, train_y)\n",
    "dtest = xgb.DMatrix(data_test.iloc[:, 1:].values)\n",
    "\n",
    "# xgboost, cross-validation\n",
    "cv_result = xgb.cv(xgb_params, \n",
    "                   dtrain, \n",
    "                   num_boost_round=700, # increase to have better results (~700)\n",
    "                   early_stopping_rounds=50,\n",
    "                   verbose_eval=50, \n",
    "                   show_stdv=False\n",
    "                  )\n",
    "\n",
    "num_boost_rounds = len(cv_result)\n",
    "print(num_boost_rounds)\n",
    "\n",
    "# train model\n",
    "model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_boost_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2_score(dtrain.get_label(), model.predict(dtrain)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
